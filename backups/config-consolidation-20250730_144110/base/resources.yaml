# Resource Configuration
# Centralized resource limits, requests, and scaling policies

resources:
  # Default Resource Profiles
  # These profiles provide consistent resource allocation patterns
  profiles:
    # Micro services (small utilities, sidecars)
    micro:
      requests:
        cpu: "50m"
        memory: "64Mi"
      limits:
        cpu: "200m"
        memory: "128Mi"

    # Small services (lightweight applications)
    small:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"

    # Medium services (standard applications)
    medium:
      requests:
        cpu: "200m"
        memory: "256Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"

    # Large services (resource-intensive applications)
    large:
      requests:
        cpu: "500m"
        memory: "1Gi"
      limits:
        cpu: "2000m"
        memory: "4Gi"

    # Extra large services (high-resource applications)
    xlarge:
      requests:
        cpu: "1000m"
        memory: "2Gi"
      limits:
        cpu: "4000m"
        memory: "8Gi"

  # Service-Specific Resource Allocations
  services:
    # Core Infrastructure
    cert_manager:
      controller:
        profile: "small"
      webhook:
        profile: "micro"
      cainjector:
        profile: "small"

    ingress_nginx:
      controller:
        requests:
          cpu: "100m"
          memory: "256Mi"
        limits:
          cpu: "1000m"
          memory: "1Gi"
      default_backend:
        profile: "micro"

    metallb:
      speaker:
        profile: "micro"
      controller:
        profile: "small"

    longhorn:
      manager:
        requests:
          cpu: "100m"
          memory: "256Mi"
        limits:
          cpu: "500m"
          memory: "512Mi"
      driver:
        profile: "small"
      ui:
        profile: "micro"

    # Application Services
    gitlab:
      webservice:
        requests:
          cpu: "1000m"
          memory: "6Gi"
        limits:
          cpu: "2000m"
          memory: "12Gi"
      sidekiq:
        requests:
          cpu: "500m"
          memory: "2Gi"
        limits:
          cpu: "1000m"
          memory: "4Gi"
      gitaly:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      redis:
        profile: "medium"
      postgresql:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "1000m"
          memory: "2Gi"

    keycloak:
      main:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"
      postgresql:
        profile: "medium"

    # Monitoring Stack
    prometheus:
      server:
        requests:
          cpu: "500m"
          memory: "2Gi"
        limits:
          cpu: "2000m"
          memory: "8Gi"
      node_exporter:
        profile: "micro"
      kube_state_metrics:
        profile: "small"

    grafana:
      main:
        profile: "medium"

    loki:
      main:
        requests:
          cpu: "200m"
          memory: "1Gi"
        limits:
          cpu: "1000m"
          memory: "4Gi"
      promtail:
        profile: "micro"

    alertmanager:
      main:
        profile: "small"

    # AI/ML Services
    jupyter:
      lab:
        requests:
          cpu: "500m"
          memory: "1Gi"
        limits:
          cpu: "2000m"
          memory: "4Gi"

    ollama:
      main:
        requests:
          cpu: "1000m"
          memory: "2Gi"
        limits:
          cpu: "4000m"
          memory: "8Gi"
      webui:
        requests:
          cpu: "200m"
          memory: "512Mi"
        limits:
          cpu: "1000m"
          memory: "2Gi"

  # Horizontal Pod Autoscaler (HPA) Settings
  autoscaling:
    # Default HPA configuration
    defaults:
      min_replicas: 1
      max_replicas: 10
      target_cpu_utilization: 70
      target_memory_utilization: 80
      scale_up_stabilization: "60s"
      scale_down_stabilization: "300s"

    # Service-specific HPA settings
    services:
      gitlab_webservice:
        min_replicas: 2
        max_replicas: 5
        target_cpu_utilization: 60

      keycloak:
        min_replicas: 2
        max_replicas: 4
        target_cpu_utilization: 70

      ingress_nginx:
        min_replicas: 2
        max_replicas: 6
        target_cpu_utilization: 60

  # Vertical Pod Autoscaler (VPA) Settings
  vertical_autoscaling:
    # Default VPA configuration
    defaults:
      update_mode: "Auto" # or "Off", "Initial", "Recreation"
      min_allowed:
        cpu: "50m"
        memory: "64Mi"
      max_allowed:
        cpu: "4000m"
        memory: "8Gi"

    # Services that should use VPA
    enabled_services:
      - "prometheus"
      - "loki"
      - "gitlab-sidekiq"

  # Quality of Service (QoS) Classes
  # Kubernetes assigns QoS classes based on resource requests/limits
  qos_guidance:
    # Guaranteed QoS (requests == limits)
    # Use for critical system components
    guaranteed:
      - "kube-system" # namespace
      - "cert-manager"
      - "ingress-nginx-controller"

    # Burstable QoS (requests < limits or only requests specified)
    # Use for most applications
    burstable:
      - "gitlab"
      - "keycloak"
      - "monitoring"

    # BestEffort QoS (no requests or limits)
    # Use for non-critical batch jobs only
    besteffort:
      - "cleanup-jobs"
      - "backup-jobs"

  # Resource Quotas per Environment
  quotas:
    # Development environment quotas
    development:
      namespace_defaults:
        requests.cpu: "2"
        requests.memory: "4Gi"
        limits.cpu: "4"
        limits.memory: "8Gi"
        persistentvolumeclaims: "20"
        pods: "50"

    # Staging environment quotas
    staging:
      namespace_defaults:
        requests.cpu: "4"
        requests.memory: "8Gi"
        limits.cpu: "8"
        limits.memory: "16Gi"
        persistentvolumeclaims: "30"
        pods: "100"

    # Production environment quotas
    production:
      namespace_defaults:
        requests.cpu: "8"
        requests.memory: "16Gi"
        limits.cpu: "16"
        limits.memory: "32Gi"
        persistentvolumeclaims: "50"
        pods: "200"

  # Node Resource Allocation
  node_allocation:
    # System reserved resources (kubelet, OS, etc.)
    system_reserved:
      cpu: "100m"
      memory: "512Mi"
      ephemeral_storage: "2Gi"

    # Kubernetes reserved resources
    kube_reserved:
      cpu: "100m"
      memory: "512Mi"
      ephemeral_storage: "2Gi"

    # Eviction thresholds
    eviction_thresholds:
      memory_available: "200Mi"
      nodefs_available: "10%"
      imagefs_available: "15%"

  # Performance Tuning
  performance:
    # CPU management policies
    cpu_manager:
      policy: "none" # or "static" for guaranteed pods

    # Memory management
    memory_manager:
      policy: "None" # or "Static"

    # Topology manager
    topology_manager:
      policy: "none" # or "best-effort", "restricted", "single-numa-node"
